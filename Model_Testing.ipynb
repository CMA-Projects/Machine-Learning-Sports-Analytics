{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv('data/PGA_STAT_2024_ALL_DATA.csv')\n",
    "\n",
    "# Soer df by column name\n",
    "df.sort_index(axis = 1, inplace=True)\n",
    "\n",
    "# list of percent columns\n",
    "list = ['Fairway%','GIR%','GIR_off_Fairway%',\n",
    "        'GIR_on_Fairway%','Putting_Birdie_Conversions',\n",
    "        'Scrambling%','Scrambling_Rough%','Scrambling_Sand%']\n",
    "for col in list:\n",
    "    df[col] = df[col].str.rstrip('%').astype('float') / 100\n",
    "\n",
    "# Make a list of column names that we want to remove\n",
    "columns_to_drop = ['REMOVE10a','REMOVE10b','REMOVE10c','REMOVE10d',\n",
    "                  'REMOVE11a','REMOVE11b','REMOVE11c','REMOVE11d',\n",
    "                  'REMOVE12a','REMOVE12b','REMOVE12c','REMOVE12d','REMOVE12e',\n",
    "                  'REMOVE13a','REMOVE13b','REMOVE13c','REMOVE13d','REMOVE13e',\n",
    "                  'REMOVE14a','REMOVE14b','REMOVE14c','REMOVE14d',\n",
    "                  'REMOVE15a','REMOVE15b','REMOVE15c','REMOVE15d',\n",
    "                  'REMOVE16a','REMOVE16b','REMOVE16c','REMOVE16d',\n",
    "                  'REMOVE17a','REMOVE17b','REMOVE17c','REMOVE17d',\n",
    "                  'REMOVE18a','REMOVE18b','REMOVE18c','REMOVE18d',\n",
    "                  'REMOVE19a','REMOVE19b','REMOVE19c','REMOVE19d',\n",
    "                  'REMOVE1a','REMOVE1b','REMOVE1c','REMOVE1d',\n",
    "                  'REMOVE20a','REMOVE20b','REMOVE20c','REMOVE20d',\n",
    "                  'REMOVE21a','REMOVE21b','REMOVE21c','REMOVE21d','REMOVE21e','REMOVE21f',\n",
    "                  'REMOVE2a','REMOVE2b','REMOVE2c','REMOVE2d',\n",
    "                  'REMOVE3a','REMOVE3b','REMOVE3c','REMOVE3d',\n",
    "                  'REMOVE4a','REMOVE4b','REMOVE4c','REMOVE4d',\n",
    "                  'REMOVE5a','REMOVE5b','REMOVE5c','REMOVE5d',\n",
    "                  'REMOVE6a','REMOVE6b','REMOVE6c','REMOVE6d',\n",
    "                  'REMOVE7a','REMOVE7b','REMOVE7c','REMOVE7d',\n",
    "                  'REMOVE8a','REMOVE8b','REMOVE8c','REMOVE8d',\n",
    "                  'REMOVE9a','REMOVE9b','REMOVE9c','REMOVE9d',\n",
    "                  'PLAYER'\n",
    "                  ]\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns = columns_to_drop, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = df[['SG_APP_AVG']]\n",
    "target1 = df[['Strokes_Adj_AVG']]\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, target1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "features2 = df[['SG_ARG_AVG']]\n",
    "target2 = df[['Strokes_Adj_AVG']]\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, target2, test_size = 0.2, random_state = 42)\n",
    "\n",
    "features3 = df[['SG_DRIVE_AVG']]\n",
    "target3 = df[['Strokes_Adj_AVG']]\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(features3, target3, test_size = 0.2, random_state = 42)\n",
    "\n",
    "features4 = df[['SG_PUTTING_AVG']]\n",
    "target4 = df[['Strokes_Adj_AVG']]\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(features4, target4, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG_APP vs Strokes:\n",
      "Mean Squared Error: 0.3241495153949111\n",
      "R^2 Score: 0.48417314679566126\n",
      "SG_ARG_AVG vs Strokes:\n",
      "Mean Squared Error: 0.4667238429303513\n",
      "R^2 Score: 0.25729121969873914\n",
      "SG_DRIVE_AVG vs Strokes:\n",
      "Mean Squared Error: 0.45631117700642626\n",
      "R^2 Score: 0.27386114327386046\n",
      "SG_PUTTING_AVG vs Strokes:\n",
      "Mean Squared Error: 0.5149909474844374\n",
      "R^2 Score: 0.18048262529104275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Sports-Analytics-Machine-Learning/models/Linear_SG_PUTTING_AVG.h5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import methods created in the utils folder\n",
    "from utils.metrics import evaluate_model\n",
    "import joblib\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "\n",
    "model_linear.fit(X_train1, y_train1)\n",
    "y_pred_linear1 = model_linear.predict(X_test1)\n",
    "mse_linear1, r2_linear1 = evaluate_model(y_test1, y_pred_linear1)\n",
    "print(\"SG_APP vs Strokes:\")\n",
    "print(f\"Mean Squared Error: {mse_linear1}\")\n",
    "print(f\"R^2 Score: {r2_linear1}\")\n",
    "joblib_file = '../Sports-Analytics-Machine-Learning/models/Linear_SG_APP.h5'\n",
    "joblib.dump(model_linear, joblib_file)\n",
    "\n",
    "model_linear.fit(X_train2, y_train2)\n",
    "y_pred_linear2 = model_linear.predict(X_test2)\n",
    "mse_linear2, r2_linear2 = evaluate_model(y_test2, y_pred_linear2)\n",
    "print(\"SG_ARG_AVG vs Strokes:\")\n",
    "print(f\"Mean Squared Error: {mse_linear2}\")\n",
    "print(f\"R^2 Score: {r2_linear2}\")\n",
    "joblib_file = '../Sports-Analytics-Machine-Learning/models/Linear_SG_ARG_AVG.h5'\n",
    "joblib.dump(model_linear, joblib_file)\n",
    "\n",
    "model_linear.fit(X_train3, y_train3)\n",
    "y_pred_linear3 = model_linear.predict(X_test3)\n",
    "mse_linear3, r2_linear3 = evaluate_model(y_test3, y_pred_linear3)\n",
    "print(\"SG_DRIVE_AVG vs Strokes:\")\n",
    "print(f\"Mean Squared Error: {mse_linear3}\")\n",
    "print(f\"R^2 Score: {r2_linear3}\")\n",
    "joblib_file = '../Sports-Analytics-Machine-Learning/models/Linear_SG_DRIVE_AVG.h5'\n",
    "joblib.dump(model_linear, joblib_file)\n",
    "\n",
    "model_linear.fit(X_train4, y_train4)\n",
    "y_pred_linear4 = model_linear.predict(X_test4)\n",
    "mse_linear4, r2_linear4 = evaluate_model(y_test4, y_pred_linear4)\n",
    "print(\"SG_PUTTING_AVG vs Strokes:\")\n",
    "print(f\"Mean Squared Error: {mse_linear4}\")\n",
    "print(f\"R^2 Score: {r2_linear4}\")\n",
    "joblib_file = '../Sports-Analytics-Machine-Learning/models/Linear_SG_PUTTING_AVG.h5'\n",
    "joblib.dump(model_linear, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70.50271694]]\n",
      "[[69.56569753]]\n",
      "[[72.27825648]]\n",
      "[[70.71545856]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO load model from joblib\n",
    "# Load the model\n",
    "joblib_file1 = '../Sports-Analytics-Machine-Learning/models/Linear_SG_APP.h5'\n",
    "joblib_file2 = '../Sports-Analytics-Machine-Learning/models/Linear_SG_ARG_AVG.h5'\n",
    "joblib_file3 = '../Sports-Analytics-Machine-Learning/models/Linear_SG_DRIVE_AVG.h5'\n",
    "joblib_file4 = '../Sports-Analytics-Machine-Learning/models/Linear_SG_PUTTING_AVG.h5'\n",
    "\n",
    "loaded_model_SG_APP = joblib.load(joblib_file1)\n",
    "loaded_model_SG_ARG_AVG = joblib.load(joblib_file2)\n",
    "loaded_model_SG_DRIVE_AVG = joblib.load(joblib_file3)\n",
    "loaded_model_SG_PUTTING_AVG = joblib.load(joblib_file4)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "sg_app_var = np.array([[0.5]])\n",
    "sg_arg_avg_var = np.array([[1.2]])\n",
    "sg_drive_avg_var = np.array([[-1.3]])\n",
    "sg_putting_avg_var = np.array([[0.6]])\n",
    "\n",
    "new_prediction_sg_app_var = loaded_model_SG_APP.predict(sg_app_var)\n",
    "new_prediction_sg_arg_avg_var = loaded_model_SG_ARG_AVG.predict(sg_arg_avg_var)\n",
    "new_prediction_sg_drive_avg_var = loaded_model_SG_DRIVE_AVG.predict(sg_drive_avg_var)\n",
    "new_prediction_sg_putting_avg_var = loaded_model_SG_PUTTING_AVG.predict(sg_putting_avg_var)\n",
    "\n",
    "print(new_prediction_sg_app_var)\n",
    "print(new_prediction_sg_arg_avg_var)\n",
    "print(new_prediction_sg_drive_avg_var)\n",
    "print(new_prediction_sg_putting_avg_var)\n",
    "\n",
    "# Flatten the predicted values b/c they are 2d arrays\n",
    "#new_prediction_sg_app_var = new_prediction_sg_app_var.flatten().astype(int)\n",
    "#new_prediction_sg_arg_avg_var = new_prediction_sg_arg_avg_var.flatten().astype(int)\n",
    "#new_prediction_sg_drive_avg_var = new_prediction_sg_drive_avg_var.flatten().astype(int)\n",
    "#new_prediction_sg_putting_avg_var = new_prediction_sg_putting_avg_var.flatten().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 4], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m input4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(new_prediction_sg_putting_avg_var[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Loading the model to make predictions\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Sports-Analytics-Machine-Learning/models/NN_4Input.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m new_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[input1, input2, input3, input4]])\n\u001b[0;32m     15\u001b[0m new_predictions \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(new_data)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\CMA\\ML Sports Analytics\\Sports-Analytics-Machine-Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 4], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "# Ecample of how to use the loaded model and use it to predict\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "input1 = int(new_prediction_sg_app_var[0,0])\n",
    "input2 = int(new_prediction_sg_arg_avg_var[0,0])\n",
    "input3 = int(new_prediction_sg_drive_avg_var[0,0])\n",
    "input4 = int(new_prediction_sg_putting_avg_var[0,0])\n",
    "\n",
    "# Loading the model to make predictions\n",
    "loaded_model = load_model('../Sports-Analytics-Machine-Learning/models/NN_4Input.h5')\n",
    "\n",
    "\n",
    "new_data = np.array([[input1, input2, input3, input4]])\n",
    "\n",
    "new_predictions = loaded_model.predict(new_data)\n",
    "\n",
    "print(new_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
